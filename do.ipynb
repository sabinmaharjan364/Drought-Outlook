{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully: /Users/sabinmaharjan/projects/python/do/static/result/nc/1_months/10_Final_2024.nc\n",
      "Value counts for 1-month outlook:\n",
      "Value: 1.0, Count: 238464\n",
      "Value: 2.0, Count: 3440\n",
      "Value: 3.0, Count: 962\n",
      "Value: 4.0, Count: 2200\n",
      "Value: 5.0, Count: 12349\n",
      "Value: 6.0, Count: 16147\n",
      "Value: nan, Count: 299159\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataArray' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 143\u001b[0m\n\u001b[1;32m    140\u001b[0m output_path_1month \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sabinmaharjan/projects/python/do/static/result/nc/1_months/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_month\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Final_2024.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m output_path_3month \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sabinmaharjan/projects/python/do/static/result/nc/3_months/app\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_month\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Final_2024.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 143\u001b[0m \u001b[43mprocess_drought_outlook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcdi_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path_1month\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path_3month\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m, in \u001b[0;36mprocess_drought_outlook\u001b[0;34m(cdi_path, rain_path, output_path_1month, output_path_3month)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Process 3-month average outlook\u001b[39;00m\n\u001b[1;32m    116\u001b[0m rain_avg_3month \u001b[38;5;241m=\u001b[39m calculate_3month_average(ds_rain, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpercentage_of_ensembles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m rain_df_3month \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_rain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlongitude\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_rain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatitude\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrain_avg_3month\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m process_outlook(cdi_df, rain_df_3month, ds_cdi, ds_rain\u001b[38;5;241m.\u001b[39mtime[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, output_path_3month, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3-month average\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m, in \u001b[0;36mcreate_dataframe\u001b[0;34m(lon, lat, data, columns)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a DataFrame from grid data.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m lon_grid, lat_grid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(lon, lat)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m: lon_grid\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m: lat_grid\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m---> 41\u001b[0m     columns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]: \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m()\n\u001b[1;32m     42\u001b[0m })\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/xarray/core/common.py:278\u001b[0m, in \u001b[0;36mAttrAccessMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m source[name]\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import multiprocessing\n",
    "import datetime\n",
    "\n",
    "def load_netcdf(file_path):\n",
    "    \"\"\"Load a NetCDF file and return as xarray Dataset.\"\"\"\n",
    "    try:\n",
    "        return xr.open_dataset(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading NetCDF file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_dataset(ds, rename_dict=None):\n",
    "    \"\"\"Preprocess the dataset by renaming and rounding coordinates.\"\"\"\n",
    "    if rename_dict:\n",
    "        ds = ds.rename(rename_dict)\n",
    "    ds['latitude'] = ds['latitude'].astype('float64').round(2)\n",
    "    ds['longitude'] = ds['longitude'].astype('float64').round(2)\n",
    "    return ds\n",
    "\n",
    "def extract_data_slice(ds, var_name, time_index=-1, nbins=2, time=1):\n",
    "    \"\"\"Extract a 2D slice from the dataset.\"\"\"\n",
    "    data = ds[var_name].values\n",
    "    if data.ndim == 3:\n",
    "        return data[:, :, time_index]\n",
    "    elif data.ndim == 4:\n",
    "        return data[nbins-1, time-1, :, :]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected number of dimensions: {data.ndim}\")\n",
    "\n",
    "def create_dataframe(lon, lat, data, columns):\n",
    "    \"\"\"Create a DataFrame from grid data.\"\"\"\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "    if isinstance(data, xr.DataArray):\n",
    "        data_values = data.values.flatten()\n",
    "    else:\n",
    "        data_values = data.flatten()\n",
    "    return pd.DataFrame({\n",
    "        'lon': lon_grid.flatten(),\n",
    "        'lat': lat_grid.flatten(),\n",
    "        columns[-1]: data_values\n",
    "    })\n",
    "def classify_drought(row):\n",
    "    \"\"\"Classify drought conditions based on CDI and rainfall.\"\"\"\n",
    "    cdi, rain = row['cdi'], row['rain']\n",
    "    if cdi < 0.2:\n",
    "        if rain < 50:\n",
    "            return 5 if cdi < 0.02 else 6  # Persists or Worsens\n",
    "        elif rain < 70:\n",
    "            return 5  # Persists\n",
    "        else:\n",
    "            return 2 if 0.1 <= cdi < 0.2 else 3  # Removed or Improved\n",
    "    else:\n",
    "        return 4 if rain < 30 else 1  # Develops or No drought\n",
    "\n",
    "def parallel_classify(df, num_cores):\n",
    "    \"\"\"Apply drought classification in parallel.\"\"\"\n",
    "    with Pool(num_cores) as p:\n",
    "        return p.map(classify_drought, [df.iloc[i] for i in range(df.shape[0])])\n",
    "\n",
    "def create_output_dataset(df_out, lat, lon, time):\n",
    "    \"\"\"Create xarray Dataset from output DataFrame.\"\"\"\n",
    "    da = xr.DataArray(df_out['outlook'].values.reshape(len(lat), len(lon)),\n",
    "                      coords=[('lat', lat), ('lon', lon)],\n",
    "                      dims=['lat', 'lon'],\n",
    "                      name='outlook')\n",
    "    da.attrs['varunit'] = ''\n",
    "    da.attrs['longname'] = 'drought outlook'\n",
    "    ds = da.to_dataset()\n",
    "    ds['time'] = ('time', [time])\n",
    "    return ds\n",
    "\n",
    "def save_netcdf(ds, file_path):\n",
    "    \"\"\"Save xarray Dataset as NetCDF file.\"\"\"\n",
    "    try:\n",
    "        ds.to_netcdf(file_path, mode='w')\n",
    "        print(f\"File saved successfully: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving NetCDF file {file_path}: {e}\")\n",
    "\n",
    "def print_value_counts(da):\n",
    "    \"\"\"Print value counts of the DataArray.\"\"\"\n",
    "    unique_values, counts = np.unique(da.values.flatten(), return_counts=True)\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        print(f\"Value: {value}, Count: {count}\")\n",
    "\n",
    "def calculate_3month_average(ds, var_name):\n",
    "    \"\"\"Calculate 3-month average from the dataset.\"\"\"\n",
    "    rain_var = ds[var_name]\n",
    "    first_three_months = rain_var[1, :3, :, :]\n",
    "    return first_three_months.mean(dim=\"time\")\n",
    "\n",
    "def process_drought_outlook(cdi_path, rain_path, output_path_1month, output_path_3month):\n",
    "    \"\"\"Main function to process drought outlook for both 1-month and 3-month average.\"\"\"\n",
    "    # Load and preprocess CDI data\n",
    "    ds_cdi = load_netcdf(cdi_path)\n",
    "    if ds_cdi is None:\n",
    "        return\n",
    "    ds_cdi = preprocess_dataset(ds_cdi)\n",
    "    cdi_slice = extract_data_slice(ds_cdi, \"cdi\")\n",
    "    cdi_df = create_dataframe(ds_cdi.longitude.values, ds_cdi.latitude.values, cdi_slice, ['lon', 'lat', 'cdi'])\n",
    "\n",
    "    # Load rainfall data\n",
    "    ds_rain = load_netcdf(rain_path)\n",
    "    if ds_rain is None:\n",
    "        return\n",
    "    ds_rain = preprocess_dataset(ds_rain, {'lat': 'latitude', 'lon': 'longitude'})\n",
    "\n",
    "    # Process 1-month outlook\n",
    "    rain_slice_1month = extract_data_slice(ds_rain, \"percentage_of_ensembles\")\n",
    "    rain_df_1month = create_dataframe(ds_rain.longitude.values, ds_rain.latitude.values, rain_slice_1month, ['lat', 'lon', 'rain'])\n",
    "    process_outlook(cdi_df, rain_df_1month, ds_cdi, ds_rain.time[0].values, output_path_1month, \"1-month\")\n",
    "\n",
    "\n",
    "    # Process 3-month average outlook\n",
    "    rain_avg_3month = calculate_3month_average(ds_rain, \"percentage_of_ensembles\")\n",
    "    rain_df_3month = create_dataframe(ds_rain.longitude.values, ds_rain.latitude.values, rain_avg_3month, ['lat', 'lon', 'rain'])\n",
    "    process_outlook(cdi_df, rain_df_3month, ds_cdi, ds_rain.time[0].values, output_path_3month, \"3-month average\")\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "def process_outlook(cdi_df, rain_df, ds_cdi, time, output_path, outlook_type):\n",
    "    \"\"\"Process outlook for either 1-month or 3-month average.\"\"\"\n",
    "    join_df = cdi_df.merge(rain_df, how='left', on=['lon', 'lat'])\n",
    "    rmna_df = join_df.dropna()\n",
    "    num_cores = min(multiprocessing.cpu_count(), 4)\n",
    "    classified = parallel_classify(rmna_df, num_cores)\n",
    "\n",
    "    df_out = pd.DataFrame({'lat': cdi_df['lat'], 'lon': cdi_df['lon'], 'outlook': np.nan})\n",
    "    df_out.loc[rmna_df.index, 'outlook'] = classified\n",
    "    df_out['outlook'] = df_out['outlook'].astype(np.float32)\n",
    "\n",
    "    ds_out = create_output_dataset(df_out, ds_cdi.latitude.values, ds_cdi.longitude.values, time)\n",
    "    save_netcdf(ds_out, output_path)\n",
    "    print(f\"Value counts for {outlook_type} outlook:\")\n",
    "    print_value_counts(ds_out.outlook)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_month = datetime.datetime.now().strftime(\"%m\")\n",
    "    cdi_path = \"/Users/sabinmaharjan/projects/python/do/static/file/cdi_1.nc\"\n",
    "    rain_path = f\"/Users/sabinmaharjan/projects/python/do/static/file/p_atmos_q5_pr_s_maq5_pumedian_2024{current_month}01_rt.nc\"\n",
    "    output_path_1month = f\"/Users/sabinmaharjan/projects/python/do/static/result/nc/1_months/{current_month}_Final_2024.nc\"\n",
    "    output_path_3month = f\"/Users/sabinmaharjan/projects/python/do/static/result/nc/3_months/app{current_month}_Final_2024.nc\"\n",
    "\n",
    "    \n",
    "\n",
    "    process_drought_outlook(cdi_path, rain_path, output_path_1month, output_path_3month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
